[dom 09 nov 2025 23:04:26 -03] Servidor iniciado na porta 5001
2025-11-09 23:04:27.206150: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:04:29.598209: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:04:30.043839: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
>> TensorFlow configurado para usar EXCLUSIVAMENTE CPU.
>> Modelo de IA carregado com sucesso!
>> Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5001
 * Running on http://192.168.0.234:5001
[33mPress CTRL+C to quit[0m
192.168.0.111 - - [09/Nov/2025 23:05:08] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:05:09] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:05:09] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:05:10] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:05:10] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:05:10] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:05:10] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:05:10] "GET /index HTTP/1.1" 200 -
>> C√¢mera iniciada: 1280x720 @ 30 FPS
‚úÖ Servidor encerrado normalmente.
ü©∂ dom 09 nov 2025 23:05:58 -03: Servidor finalizado.
==============================================================
ü©∫ VTSurgical - Sistema de Transmiss√£o Cir√∫rgica
--------------------------------------------------------------
üïí In√≠cio: dom 09 nov 2025 23:06:41 -03
üåê Porta: 5001
üìÑ Log: ./logs/vtsurgical.log
==============================================================

>> Iniciando servidor Flask na porta 5001...
[dom 09 nov 2025 23:06:41 -03] Servidor iniciado na porta 5001
2025-11-09 23:06:42.117170: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:06:44.486904: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:06:44.932211: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
>> TensorFlow configurado para usar EXCLUSIVAMENTE CPU.
>> Modelo de IA carregado com sucesso!
>> Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5001
 * Running on http://192.168.0.234:5001
[33mPress CTRL+C to quit[0m
>> C√¢mera iniciada: 1280x720 @ 30 FPS
192.168.0.111 - - [09/Nov/2025 23:08:20] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:13:07] "[32mGET / HTTP/1.1[0m" 302 -
192.168.0.111 - - [09/Nov/2025 23:13:07] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:13:12] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:13:12] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
192.168.0.111 - - [09/Nov/2025 23:13:16] "[32mGET / HTTP/1.1[0m" 302 -
192.168.0.111 - - [09/Nov/2025 23:13:16] "GET /index HTTP/1.1" 200 -
/home/vtsurgical/Documentos/stream/stream.sh, linha 61: 520157 Morto                   "$PYTHON_BIN" webstream_linux.py "$PORT_ARG" >> "$LOG_FILE" 2>&1
‚ö†Ô∏è  Servidor caiu com c√≥digo 137. Reiniciando em 5 segundos...
‚ö†Ô∏è  Servidor caiu com c√≥digo 137. Reiniciando em 5 segundos...
2025-11-09 23:15:09.030242: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:15:11.438074: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:15:11.894855: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
>> TensorFlow configurado para usar EXCLUSIVAMENTE CPU.
>> Modelo de IA carregado com sucesso!
>> Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5001
 * Running on http://192.168.0.234:5001
[33mPress CTRL+C to quit[0m
>> C√¢mera iniciada: 1280x720 @ 30 FPS
[dom 09 nov 2025 23:15:14 -03] Servidor iniciado na porta 5001
2025-11-09 23:15:15.090408: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:15:17.777117: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:15:18.450933: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
[ WARN:0@4.928] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
[ WARN:0@4.928] global cap.cpp:478 open VIDEOIO(V4L2): backend is generally available but can't be used to capture by index
[ WARN:0@4.929] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
[ERROR:0@4.930] global obsensor_uvc_stream_channel.cpp:163 getStreamChannelGroup Camera index out of range
>> TensorFlow configurado para usar EXCLUSIVAMENTE CPU.
>> Modelo de IA carregado com sucesso!
ERRO: N√£o foi poss√≠vel abrir a c√¢mera.
Falha ao iniciar captura de v√≠deo.
>> Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
Address already in use
Port 5001 is in use by another program. Either identify and stop that program, or start the server with a different port.
‚ö†Ô∏è  Servidor caiu com c√≥digo 1. Reiniciando em 5 segundos...
2025-11-09 23:15:26.176047: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
192.168.0.111 - - [09/Nov/2025 23:15:27] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:15:28] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:15:29] "GET /index HTTP/1.1" 200 -
2025-11-09 23:15:29.653276: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:15:30.151594: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
[ WARN:0@5.564] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
[ WARN:0@5.564] global cap.cpp:478 open VIDEOIO(V4L2): backend is generally available but can't be used to capture by index
>> TensorFlow configurado para usar EXCLUSIVAMENTE CPU.
>> Modelo de IA carregado com sucesso!
>> Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[ WARN:0@5.565] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
Address already in use
Port 5001 is in use by another program. Either identify and stop that program, or start the server with a different port.
[ERROR:0@5.566] global obsensor_uvc_stream_channel.cpp:163 getStreamChannelGroup Camera index out of range
terminate called without an active exception
‚ö†Ô∏è  Servidor caiu com c√≥digo 134. Reiniciando em 5 segundos...
2025-11-09 23:15:37.074026: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:15:40.536726: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:15:41.140609: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
[ WARN:0@5.798] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
[ WARN:0@5.798] global cap.cpp:478 open VIDEOIO(V4L2): backend is generally available but can't be used to capture by index
[ WARN:0@5.798] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
[ERROR:0@5.799] global obsensor_uvc_stream_channel.cpp:163 getStreamChannelGroup Camera index out of range
>> TensorFlow configurado para usar EXCLUSIVAMENTE CPU.
>> Modelo de IA carregado com sucesso!
ERRO: N√£o foi poss√≠vel abrir a c√¢mera.
Falha ao iniciar captura de v√≠deo.
>> Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
Address already in use
Port 5001 is in use by another program. Either identify and stop that program, or start the server with a different port.
‚ö†Ô∏è  Servidor caiu com c√≥digo 1. Reiniciando em 5 segundos...
2025-11-09 23:15:48.834435: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:15:51.897860: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:15:52.377506: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
[ WARN:0@5.302] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
[ WARN:0@5.302] global cap.cpp:478 open VIDEOIO(V4L2): backend is generally available but can't be used to capture by index
>> TensorFlow configurado para usar EXCLUSIVAMENTE CPU.
>> Modelo de IA carregado com sucesso!
>> Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
[ WARN:0@5.303] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
 * Debug mode: off
Address already in use
Port 5001 is in use by another program. Either identify and stop that program, or start the server with a different port.
[ERROR:0@5.303] global obsensor_uvc_stream_channel.cpp:163 getStreamChannelGroup Camera index out of range
terminate called without an active exception
‚ö†Ô∏è  Servidor caiu com c√≥digo 134. Reiniciando em 5 segundos...
2025-11-09 23:15:59.335522: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
Traceback (most recent call last):
  File "/home/vtsurgical/Documentos/stream/webstream_linux.py", line 12, in <module>
    import tensorflow as tf
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/tensorflow/__init__.py", line 49, in <module>
    from tensorflow._api.v2 import __internal__
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/__init__.py", line 8, in <module>
    from tensorflow._api.v2.__internal__ import autograph
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py", line 9, in <module>
    from tensorflow.python.autograph.impl.api import tf_convert # line: 493
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/tensorflow/python/autograph/impl/api.py", line 32, in <module>
    from tensorflow.python.autograph.converters import control_flow
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/tensorflow/python/autograph/converters/control_flow.py", line 23, in <module>
    from tensorflow.python.autograph.pyct import origin_info
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/tensorflow/python/autograph/pyct/origin_info.py", line 17, in <module>
    import difflib
  File "/usr/lib/python3.13/difflib.py", line 44, in <module>
    class SequenceMatcher:
    ...<618 lines>...
        __class_getitem__ = classmethod(GenericAlias)
  File "/usr/lib/python3.13/difflib.py", line 663, in SequenceMatcher
    __class_getitem__ = classmethod(GenericAlias)
KeyboardInterrupt
[dom 09 nov 2025 23:16:22 -03] Servidor iniciado na porta 5001
2025-11-09 23:16:23.626666: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:16:26.975081: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:16:27.608517: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
[ WARN:0@5.661] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
[ WARN:0@5.661] global cap.cpp:478 open VIDEOIO(V4L2): backend is generally available but can't be used to capture by index
[ WARN:0@5.661] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
>> TensorFlow configurado para usar EXCLUSIVAMENTE CPU.
>> Modelo de IA carregado com sucesso!
>> Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
Address already in use
Port 5001 is in use by another program. Either identify and stop that program, or start the server with a different port.
[ERROR:0@5.663] global obsensor_uvc_stream_channel.cpp:163 getStreamChannelGroup Camera index out of range
terminate called without an active exception
‚ö†Ô∏è  Servidor caiu com c√≥digo 134. Reiniciando em 5 segundos...
2025-11-09 23:16:34.747497: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:16:38.072569: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:16:38.709544: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
[ WARN:0@5.744] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
[ WARN:0@5.744] global cap.cpp:478 open VIDEOIO(V4L2): backend is generally available but can't be used to capture by index
>> TensorFlow configurado para usar EXCLUSIVAMENTE CPU.
>> Modelo de IA carregado com sucesso!
>> Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[ WARN:0@5.745] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
Address already in use
Port 5001 is in use by another program. Either identify and stop that program, or start the server with a different port.
[ERROR:0@5.746] global obsensor_uvc_stream_channel.cpp:163 getStreamChannelGroup Camera index out of range
terminate called without an active exception
‚ö†Ô∏è  Servidor caiu com c√≥digo 134. Reiniciando em 5 segundos...
Traceback (most recent call last):
  File "/home/vtsurgical/Documentos/stream/webstream_linux.py", line 2, in <module>
    import cv2
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/cv2/__init__.py", line 11, in <module>
    import numpy
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/numpy/__init__.py", line 181, in <module>
    from . import lib
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/numpy/lib/__init__.py", line 17, in <module>
    from . import scimath
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/numpy/lib/scimath.py", line 1, in <module>
    from ._scimath_impl import (
    ...<2 lines>...
    )
  File "<frozen importlib._bootstrap>", line 1357, in _find_and_load
  File "<frozen importlib._bootstrap>", line 421, in __exit__
  File "<frozen importlib._bootstrap>", line 378, in release
KeyboardInterrupt
/home/vtsurgical/Documentos/stream/stream.sh, linha 61: 537096 Morto                   "$PYTHON_BIN" webstream_linux.py "$PORT_ARG" >> "$LOG_FILE" 2>&1
‚ö†Ô∏è  Servidor caiu com c√≥digo 137. Reiniciando em 5 segundos...
‚ö†Ô∏è  Servidor caiu com c√≥digo 137. Reiniciando em 5 segundos...
2025-11-09 23:18:32.551801: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:18:34.916950: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:18:35.358830: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
>> TensorFlow configurado para usar EXCLUSIVAMENTE CPU.
>> Modelo de IA carregado com sucesso!
>> Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5001
 * Running on http://192.168.0.234:5001
[33mPress CTRL+C to quit[0m
>> C√¢mera iniciada: 1280x720 @ 30 FPS
/home/vtsurgical/Documentos/stream/stream.sh, linha 61: 543503 Morto                   "$PYTHON_BIN" webstream_linux.py "$PORT_ARG" >> "$LOG_FILE" 2>&1
‚ö†Ô∏è  Servidor caiu com c√≥digo 137. Reiniciando em 5 segundos...
‚ö†Ô∏è  Servidor caiu com c√≥digo 137. Reiniciando em 5 segundos...
2025-11-09 23:20:11.837396: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:20:14.201265: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:20:14.643986: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
>> TensorFlow configurado para usar EXCLUSIVAMENTE CPU.
>> Modelo de IA carregado com sucesso!
>> Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5001
 * Running on http://192.168.0.234:5001
[33mPress CTRL+C to quit[0m
>> C√¢mera iniciada: 1280x720 @ 30 FPS
[dom 09 nov 2025 23:22:40 -03] Servidor iniciado na porta 5001
2025-11-09 23:22:41.140921: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:22:44.454789: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
192.168.0.111 - - [09/Nov/2025 23:22:44] "GET /index HTTP/1.1" 200 -
2025-11-09 23:22:45.080066: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
[ WARN:0@5.748] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
[ WARN:0@5.748] global cap.cpp:478 open VIDEOIO(V4L2): backend is generally available but can't be used to capture by index
>> TensorFlow configurado para usar EXCLUSIVAMENTE CPU.
>> Modelo de IA carregado com sucesso!
>> Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[ WARN:0@5.749] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
Address already in use
Port 5001 is in use by another program. Either identify and stop that program, or start the server with a different port.
[ERROR:0@5.750] global obsensor_uvc_stream_channel.cpp:163 getStreamChannelGroup Camera index out of range
terminate called without an active exception
‚ö†Ô∏è  Servidor caiu com c√≥digo 134. Reiniciando em 5 segundos...
192.168.0.111 - - [09/Nov/2025 23:22:47] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:22:47] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:22:47] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:22:48] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:22:48] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:22:48] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:22:48] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:22:48] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:22:48] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:22:48] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:22:49] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:22:49] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:22:49] "GET /index HTTP/1.1" 200 -
2025-11-09 23:22:52.105590: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:22:55.411616: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:22:55.910550: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
[ WARN:0@5.512] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
[ WARN:0@5.512] global cap.cpp:478 open VIDEOIO(V4L2): backend is generally available but can't be used to capture by index
>> TensorFlow configurado para usar EXCLUSIVAMENTE CPU.
>> Modelo de IA carregado com sucesso!
>> Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[ WARN:0@5.513] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
Address already in use
Port 5001 is in use by another program. Either identify and stop that program, or start the server with a different port.
[ERROR:0@5.514] global obsensor_uvc_stream_channel.cpp:163 getStreamChannelGroup Camera index out of range
terminate called without an active exception
‚ö†Ô∏è  Servidor caiu com c√≥digo 134. Reiniciando em 5 segundos...
2025-11-09 23:23:02.965609: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:23:06.131530: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:23:06.778827: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
[ WARN:0@5.551] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
[ WARN:0@5.552] global cap.cpp:478 open VIDEOIO(V4L2): backend is generally available but can't be used to capture by index
[ WARN:0@5.552] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
>> TensorFlow configurado para usar EXCLUSIVAMENTE CPU.
>> Modelo de IA carregado com sucesso!
>> Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
Address already in use
Port 5001 is in use by another program. Either identify and stop that program, or start the server with a different port.
[ERROR:0@5.553] global obsensor_uvc_stream_channel.cpp:163 getStreamChannelGroup Camera index out of range
ERRO: N√£o foi poss√≠vel abrir a c√¢mera.
Falha ao iniciar captura de v√≠deo.
‚ö†Ô∏è  Servidor caiu com c√≥digo 1. Reiniciando em 5 segundos...
2025-11-09 23:23:14.427039: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:23:17.778342: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:23:18.410346: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
[ WARN:0@5.494] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
[ WARN:0@5.494] global cap.cpp:478 open VIDEOIO(V4L2): backend is generally available but can't be used to capture by index
>> TensorFlow configurado para usar EXCLUSIVAMENTE CPU.
>> Modelo de IA carregado com sucesso!
>> Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
Address already in use
Port 5001 is in use by another program. Either identify and stop that program, or start the server with a different port.
[ WARN:0@5.495] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
[ERROR:0@5.496] global obsensor_uvc_stream_channel.cpp:163 getStreamChannelGroup Camera index out of range
terminate called without an active exception
‚ö†Ô∏è  Servidor caiu com c√≥digo 134. Reiniciando em 5 segundos...
2025-11-09 23:23:25.337647: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:23:28.814799: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:23:29.377498: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
[ WARN:0@5.730] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
[ WARN:0@5.730] global cap.cpp:478 open VIDEOIO(V4L2): backend is generally available but can't be used to capture by index
[ WARN:0@5.734] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
[ERROR:0@5.735] global obsensor_uvc_stream_channel.cpp:163 getStreamChannelGroup Camera index out of range
>> TensorFlow configurado para usar EXCLUSIVAMENTE CPU.
>> Modelo de IA carregado com sucesso!
>> Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
ERRO: N√£o foi poss√≠vel abrir a c√¢mera.
Falha ao iniciar captura de v√≠deo.
 * Debug mode: off
Address already in use
Port 5001 is in use by another program. Either identify and stop that program, or start the server with a different port.
‚ö†Ô∏è  Servidor caiu com c√≥digo 1. Reiniciando em 5 segundos...
2025-11-09 23:23:36.968386: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:23:40.251669: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:23:40.779291: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
[ WARN:0@5.540] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
[ WARN:0@5.540] global cap.cpp:478 open VIDEOIO(V4L2): backend is generally available but can't be used to capture by index
[ WARN:0@5.540] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
>> TensorFlow configurado para usar EXCLUSIVAMENTE CPU.
>> Modelo de IA carregado com sucesso!
>> Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
Address already in use
Port 5001 is in use by another program. Either identify and stop that program, or start the server with a different port.
[ERROR:0@5.548] global obsensor_uvc_stream_channel.cpp:163 getStreamChannelGroup Camera index out of range
terminate called without an active exception
‚ö†Ô∏è  Servidor caiu com c√≥digo 134. Reiniciando em 5 segundos...
2025-11-09 23:23:47.854218: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:23:51.340794: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
Traceback (most recent call last):
  File "/home/vtsurgical/Documentos/stream/webstream_linux.py", line 12, in <module>
    import tensorflow as tf
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/tensorflow/__init__.py", line 468, in <module>
    importlib.import_module("keras.src.optimizers")
    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.13/importlib/__init__.py", line 88, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/keras/__init__.py", line 7, in <module>
    from keras import _tf_keras as _tf_keras
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/keras/_tf_keras/__init__.py", line 1, in <module>
    from keras._tf_keras import keras
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/keras/_tf_keras/keras/__init__.py", line 25, in <module>
    from keras import regularizers as regularizers
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 1022, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1143, in get_code
  File "<frozen importlib._bootstrap_external>", line 749, in _validate_timestamp_pyc
  File "<frozen importlib._bootstrap_external>", line 92, in _unpack_uint32
KeyboardInterrupt
==============================================================
ü©∫ VTSurgical - Sistema de Transmiss√£o Cir√∫rgica
--------------------------------------------------------------
üïí In√≠cio: dom 09 nov 2025 23:25:30 -03
üåê Porta: 5001
üìÑ Log: ./logs/vtsurgical.log
==============================================================

>> Iniciando servidor Flask na porta 5001...
[dom 09 nov 2025 23:25:30 -03] Servidor iniciado na porta 5001
2025-11-09 23:25:33.212437: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:25:40.800616: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:25:42.739135: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
>> TensorFlow configurado para usar EXCLUSIVAMENTE CPU.
>> Modelo de IA carregado com sucesso!
>> Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5001
 * Running on http://192.168.0.234:5001
[33mPress CTRL+C to quit[0m
>> C√¢mera iniciada: 1280x720 @ 30 FPS
192.168.0.111 - - [09/Nov/2025 23:25:49] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:25:50] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:25:51] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:25:51] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:25:51] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:25:52] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [09/Nov/2025 23:25:54] "[32mGET / HTTP/1.1[0m" 302 -
192.168.0.111 - - [09/Nov/2025 23:25:54] "GET /index HTTP/1.1" 200 -
/home/vtsurgical/Documentos/stream/stream.sh, linha 61:   944 Morto                   "$PYTHON_BIN" webstream_linux.py "$PORT_ARG" >> "$LOG_FILE" 2>&1
‚ö†Ô∏è  Servidor caiu com c√≥digo 137. Reiniciando em 5 segundos...
‚ö†Ô∏è  Servidor caiu com c√≥digo 137. Reiniciando em 5 segundos...
2025-11-09 23:29:01.960892: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:29:04.349857: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-09 23:29:04.794119: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
>> TensorFlow configurado para usar EXCLUSIVAMENTE CPU.
>> Modelo de IA carregado com sucesso!
>> Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5001
 * Running on http://192.168.0.234:5001
[33mPress CTRL+C to quit[0m
>> C√¢mera iniciada: 1280x720 @ 30 FPS
10-11-2025 00:08:56 | INFO | Configura√ß√£o carregada com sucesso.
10-11-2025 00:08:57 | INFO | Modelo de IA carregado com sucesso.
10-11-2025 00:08:57 | INFO | ‚úÖ Porta 5000 dispon√≠vel para uso.
10-11-2025 00:08:57 | INFO | Servidor Flask iniciado em http://0.0.0.0:5000
10-11-2025 00:08:57 | INFO | üö´ Falha ao abrir c√¢mera no √≠ndice 0. Tentando fallback...
10-11-2025 00:08:57 | INFO | ‚ùå Nenhuma c√¢mera dispon√≠vel.
10-11-2025 00:08:57 | INFO | Falha ao iniciar captura de v√≠deo.
192.168.0.111 - - [10/Nov/2025 00:09:09] "[32mGET / HTTP/1.1[0m" 302 -
192.168.0.111 - - [10/Nov/2025 00:09:09] "GET /login HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 00:09:09] "[36mGET /static/css/main.css HTTP/1.1[0m" 304 -
10-11-2025 00:09:20 | INFO | Usu√°rio 'hupe' logado com sucesso.
/home/vtsurgical/Documentos/stream/stream.sh, linha 61:  8101 Morto                   "$PYTHON_BIN" webstream_linux.py "$PORT_ARG" >> "$LOG_FILE" 2>&1
‚ö†Ô∏è  Servidor caiu com c√≥digo 137. Reiniciando em 5 segundos...
‚ö†Ô∏è  Servidor caiu com c√≥digo 137. Reiniciando em 5 segundos...
2025-11-10 01:32:09.143314: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-10 01:32:11.492542: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
‚ö†Ô∏è  Modelo de IA n√£o encontrado (.h5 ausente).
üé• C√¢mera iniciada: 640x480 @ 15 FPS
‚úÖ Servidor Flask iniciado em http://0.0.0.0:5000
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.234:5000
[33mPress CTRL+C to quit[0m
/home/vtsurgical/Documentos/stream/stream.sh, linha 61: 233821 Morto                   "$PYTHON_BIN" webstream_linux.py "$PORT_ARG" >> "$LOG_FILE" 2>&1
‚ö†Ô∏è  Servidor caiu com c√≥digo 137. Reiniciando em 5 segundos...
‚ö†Ô∏è  Servidor caiu com c√≥digo 137. Reiniciando em 5 segundos...
2025-11-10 01:36:07.982045: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-10 01:36:10.348297: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
‚ö†Ô∏è  Modelo de IA n√£o encontrado (.h5 ausente).
üé• C√¢mera iniciada: 640x480 @ 15 FPS
‚úÖ Servidor Flask iniciado em http://0.0.0.0:5000
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.234:5000
[33mPress CTRL+C to quit[0m
2025-11-10 01:36:12.551902: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-10 01:36:14.905844: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
‚ö†Ô∏è  Modelo de IA n√£o encontrado (.h5 ausente).
[ WARN:0@3.204] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index
[ERROR:0@3.265] global obsensor_uvc_stream_channel.cpp:163 getStreamChannelGroup Camera index out of range
üö´ Falha ao abrir c√¢mera no √≠ndice 0. Tentando fallback...
[ WARN:0@3.265] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video1): can't open camera by index
[ERROR:0@3.266] global obsensor_uvc_stream_channel.cpp:163 getStreamChannelGroup Camera index out of range
üé• C√¢mera detectada no √≠ndice 2.
‚úÖ Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5001
 * Running on http://192.168.0.234:5001
[33mPress CTRL+C to quit[0m
192.168.0.111 - - [10/Nov/2025 01:36:16] "GET /config HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:36:18] "[32mGET / HTTP/1.1[0m" 302 -
192.168.0.111 - - [10/Nov/2025 01:36:18] "GET /index HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:36:19] "GET /status_info HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:36:20] "GET /config HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:36:21] "GET /video_feed HTTP/1.1" 200 -
üé• C√¢meras dispon√≠veis: [(-1, 'Nenhuma c√¢mera detectada')]
üé• C√¢meras detectadas: [(-1, 'Nenhuma c√¢mera detectada')]
üé• C√¢meras dispon√≠veis: [(-1, 'Nenhuma c√¢mera detectada')]
üé• C√¢meras detectadas: [(-1, 'Nenhuma c√¢mera detectada')]
/home/vtsurgical/Documentos/stream/stream.sh, linha 61: 233929 Morto                   "$PYTHON_BIN" webstream_linux.py "$PORT_ARG" >> "$LOG_FILE" 2>&1
‚ö†Ô∏è  Servidor caiu com c√≥digo 137. Reiniciando em 5 segundos...
‚ö†Ô∏è  Servidor caiu com c√≥digo 137. Reiniciando em 5 segundos...
2025-11-10 01:38:15.215572: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-10 01:38:17.570213: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
‚ö†Ô∏è  Modelo de IA n√£o encontrado (.h5 ausente).
üé• C√¢mera iniciada: 640x480 @ 15 FPS
‚úÖ Servidor Flask iniciado em http://0.0.0.0:5000
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.234:5000
[33mPress CTRL+C to quit[0m
/home/vtsurgical/Documentos/stream/stream.sh, linha 61: 233991 Morto                   "$PYTHON_BIN" webstream_linux.py "$PORT_ARG" >> "$LOG_FILE" 2>&1
‚ö†Ô∏è  Servidor caiu com c√≥digo 137. Reiniciando em 5 segundos...
‚ö†Ô∏è  Servidor caiu com c√≥digo 137. Reiniciando em 5 segundos...
2025-11-10 01:42:41.403016: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-10 01:42:43.717756: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-10 01:42:44.059492: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
/home/vtsurgical/Documentos/stream/webstream_linux.py:179: DeprecationWarning: connections() is deprecated and will be removed; use net_connections() instead
  for conn in proc.connections(kind="inet"):
‚úÖ Modelo de IA carregado com sucesso!
Servidor Flask iniciado em http://0.0.0.0:5000
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.234:5000
[33mPress CTRL+C to quit[0m
2025-11-10 01:42:45.966803: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-10 01:42:48.253691: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-10 01:42:48.592674: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
‚úÖ Modelo de IA carregado com sucesso!
/home/vtsurgical/Documentos/stream/webstream_linux.py:179: DeprecationWarning: connections() is deprecated and will be removed; use net_connections() instead
  for conn in proc.connections(kind="inet"):
Servidor Flask iniciado em http://0.0.0.0:5001
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
üö´ Falha ao abrir c√¢mera /dev/video-1.
‚ùå Nenhuma c√¢mera dispon√≠vel.
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5001
 * Running on http://192.168.0.234:5001
[33mPress CTRL+C to quit[0m
192.168.0.111 - - [10/Nov/2025 01:42:52] "[32mGET /config HTTP/1.1[0m" 302 -
192.168.0.111 - - [10/Nov/2025 01:42:52] "GET /login HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:42:52] "[36mGET /static/css/main.css HTTP/1.1[0m" 304 -
192.168.0.111 - - [10/Nov/2025 01:42:59] "[32mPOST /login HTTP/1.1[0m" 302 -
192.168.0.111 - - [10/Nov/2025 01:42:59] "GET / HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:42:59] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:42:59] "GET /video_feed HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:43:04] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:43:09] "[33mGET /status_info HTTP/1.1[0m" 404 -
[2025-11-10 01:43:12,560] ERROR in app: Exception on /config [GET]
Traceback (most recent call last):
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/webstream_linux.py", line 207, in wrapper
    return f(*args, **kwargs)
  File "/home/vtsurgical/Documentos/stream/webstream_linux.py", line 278, in config
    return render_template("config.html", config=CONFIG, devices=devices, session=session)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/templating.py", line 150, in render_template
    return _render(app, template, context)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/templating.py", line 131, in _render
    rv = template.render(context)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/jinja2/environment.py", line 1295, in render
    self.environment.handle_exception()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/jinja2/environment.py", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "/home/vtsurgical/Documentos/stream/templates/config.html", line 171, in top-level template code
    {% for index, label in devices %}
    ^^^^^^^^^^^^^^^
ValueError: too many values to unpack (expected 2)
192.168.0.111 - - [10/Nov/2025 01:43:12] "[35m[1mGET /config HTTP/1.1[0m" 500 -
192.168.0.111 - - [10/Nov/2025 01:43:24] "GET /video_feed HTTP/1.1" 200 -
[2025-11-10 01:43:27,138] ERROR in app: Exception on /config [GET]
Traceback (most recent call last):
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/webstream_linux.py", line 207, in wrapper
    return f(*args, **kwargs)
  File "/home/vtsurgical/Documentos/stream/webstream_linux.py", line 278, in config
    return render_template("config.html", config=CONFIG, devices=devices, session=session)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/templating.py", line 150, in render_template
    return _render(app, template, context)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/templating.py", line 131, in _render
    rv = template.render(context)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/jinja2/environment.py", line 1295, in render
    self.environment.handle_exception()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/jinja2/environment.py", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "/home/vtsurgical/Documentos/stream/templates/config.html", line 171, in top-level template code
    {% for index, label in devices %}
    ^^^^^^^^^^^^^^^
ValueError: too many values to unpack (expected 2)
192.168.0.111 - - [10/Nov/2025 01:43:27] "[35m[1mGET /config HTTP/1.1[0m" 500 -
üö´ Falha ao abrir c√¢mera /dev/video-1.
‚ùå Nenhuma c√¢mera dispon√≠vel.
Usu√°rio 'hupe' logado com sucesso.
2025-11-10 01:46:42.963855: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-10 01:46:45.252432: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-10 01:46:45.592133: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
/home/vtsurgical/Documentos/stream/webstream_linux.py:179: DeprecationWarning: connections() is deprecated and will be removed; use net_connections() instead
  for conn in proc.connections(kind="inet"):
‚úÖ Modelo de IA carregado com sucesso!
Servidor Flask iniciado em http://0.0.0.0:5000
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.234:5000
[33mPress CTRL+C to quit[0m
192.168.0.111 - - [10/Nov/2025 01:47:10] "GET /config HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:47:23] "POST /config HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:47:29] "GET / HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:47:29] "GET /video_feed HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:47:29] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:47:34] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:47:39] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:47:44] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:47:49] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:47:54] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:47:59] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:47:59] "GET /config HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:48:02] "POST /config HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:48:08] "GET / HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:48:08] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:48:08] "GET /video_feed HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:48:13] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:48:18] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:48:23] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:48:28] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:48:33] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:48:38] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:48:38] "POST /toggle_ia HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:48:39] "GET / HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:48:39] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:48:39] "GET /video_feed HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:48:44] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:48:49] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:48:54] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:48:59] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:49:04] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:49:09] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:49:14] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:49:19] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:49:24] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:49:29] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:49:34] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:49:39] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:49:44] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:49:49] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:49:54] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:49:59] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:50:04] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:50:09] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:50:14] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:50:19] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:50:24] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:50:29] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:50:34] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:50:39] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:50:44] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:50:49] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:50:54] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:50:59] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:51:04] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:51:09] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:51:16] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:52:16] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:52:23] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:52:24] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:52:29] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:52:34] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:52:37] "GET /config HTTP/1.1" 200 -
üö´ Falha ao abrir c√¢mera /dev/video-1.
‚ùå Nenhuma c√¢mera dispon√≠vel.
2025-11-10 01:57:08.744580: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-10 01:57:11.076050: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-10 01:57:11.422804: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
/home/vtsurgical/Documentos/stream/webstream_linux.py:204: DeprecationWarning: connections() is deprecated and will be removed; use net_connections() instead
  for conn in proc.connections(kind="inet"):
‚úÖ Modelo de IA carregado com sucesso!
Servidor Flask iniciado em http://0.0.0.0:5000
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.234:5000
[33mPress CTRL+C to quit[0m
192.168.0.111 - - [10/Nov/2025 01:57:13] "GET /config HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:57:14] "GET /config HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:57:16] "GET / HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:57:16] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:57:16] "GET /video_feed HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:57:21] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:57:24] "GET /config HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:57:29] "GET / HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:57:29] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:57:29] "GET /video_feed HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:57:34] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:57:35] "POST /toggle_ia HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:57:36] "GET / HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:57:36] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:57:36] "GET /video_feed HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:57:40] "POST /toggle_ia HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:57:41] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:57:41] "GET / HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:57:41] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:57:41] "GET /video_feed HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:57:46] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:57:51] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:57:56] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:57:57] "GET /config HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:58:02] "POST /config HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:58:07] "GET / HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:58:07] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:58:07] "GET /video_feed HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:58:12] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:58:17] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:58:18] "GET /config HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:58:23] "POST /config HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:58:28] "GET / HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:58:28] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:58:28] "GET /video_feed HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 01:58:33] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:58:39] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:58:44] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:58:49] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:58:54] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:58:59] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:59:04] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:59:09] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:59:14] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:59:19] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:59:24] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:59:29] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:59:34] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:59:40] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:59:43] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:59:48] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:59:53] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 01:59:58] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:00:03] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:00:09] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:00:14] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:00:19] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:00:24] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:00:29] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:00:34] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:00:39] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:00:44] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:00:49] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:00:54] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:00:59] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:01:16] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:01:59] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:02:04] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:02:09] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:02:14] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:02:19] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:02:24] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:02:29] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:02:34] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:02:39] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:02:44] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:02:49] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:02:54] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:02:58] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:03:03] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:03:08] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:03:13] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:03:18] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:03:23] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:03:28] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:03:33] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:03:38] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:03:43] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:03:48] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:03:53] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:03:58] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:04:03] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:04:08] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:04:13] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:04:18] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:04:23] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:04:28] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:04:33] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:04:38] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:04:43] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:04:48] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:04:53] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:04:58] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:05:03] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:05:08] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:05:13] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:05:18] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:05:23] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:05:28] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:05:33] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:05:38] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:05:43] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:05:48] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:05:53] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:05:58] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:06:03] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:06:08] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:06:13] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:06:18] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:06:23] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:06:28] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:06:33] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:06:38] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:06:43] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:06:48] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:06:53] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:06:58] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:07:03] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:07:08] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:07:13] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:07:18] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:07:23] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:07:28] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:07:33] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:07:38] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:07:43] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:07:48] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:07:53] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:07:58] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:08:03] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:08:08] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:08:13] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:08:18] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:08:23] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:08:28] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:08:33] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:08:38] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:08:43] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:08:48] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:08:53] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:08:58] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:09:03] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:09:08] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:09:13] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:09:18] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:09:23] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:09:28] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:09:33] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:09:38] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:09:43] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:09:48] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:09:53] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:09:58] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:10:03] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:10:08] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:10:13] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:10:18] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:10:23] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:10:28] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:10:33] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:10:38] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:10:43] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:10:48] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:10:53] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:10:58] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:11:03] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:11:08] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:11:13] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:11:18] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:11:23] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:11:28] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:11:33] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:11:38] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:11:43] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:11:48] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:11:53] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:11:58] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:12:03] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:12:08] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:12:13] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:12:18] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:12:23] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:12:28] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:12:33] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:12:38] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:12:43] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:12:48] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:12:53] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:12:58] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:13:03] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:13:08] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:13:13] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:13:18] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:13:23] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:13:28] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:13:33] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:13:38] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:13:43] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:13:48] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:13:54] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:13:59] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:14:04] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:14:09] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:14:14] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:14:19] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:14:24] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:14:29] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:14:34] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:14:39] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:14:44] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:14:49] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:15:16] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:16:16] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:17:16] "[33mGET /status_info HTTP/1.1[0m" 404 -
192.168.0.111 - - [10/Nov/2025 02:18:16] "[33mGET /status_info HTTP/1.1[0m" 404 -
2025-11-10 08:50:23.907436: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-10 08:50:26.201632: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-10 08:50:26.543787: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
‚úÖ IA carregada com sucesso.
üåê Servidor rodando em http://0.0.0.0:5000
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.234:5000
[33mPress CTRL+C to quit[0m
unknown control 'exposure_auto'
unknown control 'gain_automatic'
üé• Codec ativo: MJPG em /dev/video0
‚úÖ C√¢mera iniciada: /dev/video0
2025-11-10 08:50:44.431653: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-10 08:50:46.734666: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-10 08:50:47.078154: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
‚úÖ IA carregada com sucesso.
üåê Servidor rodando em http://0.0.0.0:5000
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.234:5000
[33mPress CTRL+C to quit[0m
unknown control 'exposure_auto'
unknown control 'gain_automatic'
192.168.0.111 - - [10/Nov/2025 08:50:54] "[32mGET /config HTTP/1.1[0m" 302 -
192.168.0.111 - - [10/Nov/2025 08:50:54] "GET /login HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 08:50:54] "[36mGET /static/css/main.css HTTP/1.1[0m" 304 -
192.168.0.111 - - [10/Nov/2025 08:51:02] "[32mPOST /login HTTP/1.1[0m" 302 -
[2025-11-10 08:51:02,661] ERROR in app: Exception on / [GET]
Traceback (most recent call last):
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/webstream_linux.py", line 222, in wrapper
    return f(*a, **kw)
  File "/home/vtsurgical/Documentos/stream/webstream_linux.py", line 238, in index
    return render_template("index.html", config=CONFIG, ia_enabled=IA_ENABLED, session=session)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/templating.py", line 150, in render_template
    return _render(app, template, context)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/templating.py", line 131, in _render
    rv = template.render(context)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/jinja2/environment.py", line 1295, in render
    self.environment.handle_exception()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/jinja2/environment.py", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "/home/vtsurgical/Documentos/stream/templates/index.html", line 190, in top-level template code
    <a href="{{ url_for('logout') }}">üö™ Sair ({{ session['username'] }})</a>
    ^^^^^^^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1121, in url_for
    return self.handle_url_build_error(error, endpoint, values)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1110, in url_for
    rv = url_adapter.build(  # type: ignore[union-attr]
        endpoint,
    ...<3 lines>...
        force_external=_external,
    )
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/werkzeug/routing/map.py", line 924, in build
    raise BuildError(endpoint, values, method, self)
werkzeug.routing.exceptions.BuildError: Could not build url for endpoint 'logout'. Did you mean 'login' instead?
192.168.0.111 - - [10/Nov/2025 08:51:02] "[35m[1mGET / HTTP/1.1[0m" 500 -
192.168.0.111 - - [10/Nov/2025 08:51:56] "[32mGET / HTTP/1.1[0m" 302 -
192.168.0.111 - - [10/Nov/2025 08:51:56] "GET /login HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 08:51:56] "[36mGET /static/css/main.css HTTP/1.1[0m" 304 -
192.168.0.111 - - [10/Nov/2025 08:51:58] "[32mGET / HTTP/1.1[0m" 302 -
192.168.0.111 - - [10/Nov/2025 08:51:58] "GET /login HTTP/1.1" 200 -
192.168.0.111 - - [10/Nov/2025 08:51:58] "[36mGET /static/css/main.css HTTP/1.1[0m" 304 -
[2025-11-10 08:52:08,886] ERROR in app: Exception on / [GET]
Traceback (most recent call last):
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/webstream_linux.py", line 222, in wrapper
    return f(*a, **kw)
  File "/home/vtsurgical/Documentos/stream/webstream_linux.py", line 238, in index
    return render_template("index.html", config=CONFIG, ia_enabled=IA_ENABLED, session=session)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/templating.py", line 150, in render_template
    return _render(app, template, context)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/templating.py", line 131, in _render
    rv = template.render(context)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/jinja2/environment.py", line 1295, in render
    self.environment.handle_exception()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/jinja2/environment.py", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "/home/vtsurgical/Documentos/stream/templates/index.html", line 190, in top-level template code
    <a href="{{ url_for('logout') }}">üö™ Sair ({{ session['username'] }})</a>
    ^^^^^^^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1121, in url_for
    return self.handle_url_build_error(error, endpoint, values)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1110, in url_for
    rv = url_adapter.build(  # type: ignore[union-attr]
        endpoint,
    ...<3 lines>...
        force_external=_external,
    )
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/werkzeug/routing/map.py", line 924, in build
    raise BuildError(endpoint, values, method, self)
werkzeug.routing.exceptions.BuildError: Could not build url for endpoint 'logout'. Did you mean 'login' instead?
192.168.0.111 - - [10/Nov/2025 08:52:08] "[35m[1mGET / HTTP/1.1[0m" 500 -
üé• Codec ativo: MJPG em /dev/video0
‚úÖ C√¢mera iniciada: /dev/video0
2025-11-10 09:09:54.456400: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-10 09:09:56.774871: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-10 09:09:57.115670: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
‚úÖ IA carregada com sucesso.
üåê Servidor rodando em http://0.0.0.0:5000
 * Serving Flask app 'webstream_linux'
 * Debug mode: off
[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.234:5000
[33mPress CTRL+C to quit[0m
unknown control 'exposure_auto'
unknown control 'gain_automatic'
[2025-11-10 09:10:04,387] ERROR in app: Exception on / [GET]
Traceback (most recent call last):
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/webstream_linux.py", line 222, in wrapper
    return f(*a, **kw)
  File "/home/vtsurgical/Documentos/stream/webstream_linux.py", line 238, in index
    return render_template("index.html", config=CONFIG, ia_enabled=IA_ENABLED, session=session)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/templating.py", line 150, in render_template
    return _render(app, template, context)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/templating.py", line 131, in _render
    rv = template.render(context)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/jinja2/environment.py", line 1295, in render
    self.environment.handle_exception()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/jinja2/environment.py", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "/home/vtsurgical/Documentos/stream/templates/index.html", line 190, in top-level template code
    <a href="{{ url_for('logout') }}">üö™ Sair ({{ session['username'] }})</a>
    ^^^^^^^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1121, in url_for
    return self.handle_url_build_error(error, endpoint, values)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1110, in url_for
    rv = url_adapter.build(  # type: ignore[union-attr]
        endpoint,
    ...<3 lines>...
        force_external=_external,
    )
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/werkzeug/routing/map.py", line 924, in build
    raise BuildError(endpoint, values, method, self)
werkzeug.routing.exceptions.BuildError: Could not build url for endpoint 'logout'. Did you mean 'login' instead?
192.168.0.111 - - [10/Nov/2025 09:10:04] "[35m[1mGET / HTTP/1.1[0m" 500 -
[2025-11-10 09:10:05,530] ERROR in app: Exception on / [GET]
Traceback (most recent call last):
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/webstream_linux.py", line 222, in wrapper
    return f(*a, **kw)
  File "/home/vtsurgical/Documentos/stream/webstream_linux.py", line 238, in index
    return render_template("index.html", config=CONFIG, ia_enabled=IA_ENABLED, session=session)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/templating.py", line 150, in render_template
    return _render(app, template, context)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/templating.py", line 131, in _render
    rv = template.render(context)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/jinja2/environment.py", line 1295, in render
    self.environment.handle_exception()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/jinja2/environment.py", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "/home/vtsurgical/Documentos/stream/templates/index.html", line 190, in top-level template code
    <a href="{{ url_for('logout') }}">üö™ Sair ({{ session['username'] }})</a>
    ^^^^^^^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1121, in url_for
    return self.handle_url_build_error(error, endpoint, values)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1110, in url_for
    rv = url_adapter.build(  # type: ignore[union-attr]
        endpoint,
    ...<3 lines>...
        force_external=_external,
    )
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/werkzeug/routing/map.py", line 924, in build
    raise BuildError(endpoint, values, method, self)
werkzeug.routing.exceptions.BuildError: Could not build url for endpoint 'logout'. Did you mean 'login' instead?
192.168.0.111 - - [10/Nov/2025 09:10:05] "[35m[1mGET / HTTP/1.1[0m" 500 -
[2025-11-10 09:10:06,046] ERROR in app: Exception on / [GET]
Traceback (most recent call last):
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/webstream_linux.py", line 222, in wrapper
    return f(*a, **kw)
  File "/home/vtsurgical/Documentos/stream/webstream_linux.py", line 238, in index
    return render_template("index.html", config=CONFIG, ia_enabled=IA_ENABLED, session=session)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/templating.py", line 150, in render_template
    return _render(app, template, context)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/templating.py", line 131, in _render
    rv = template.render(context)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/jinja2/environment.py", line 1295, in render
    self.environment.handle_exception()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/jinja2/environment.py", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "/home/vtsurgical/Documentos/stream/templates/index.html", line 190, in top-level template code
    <a href="{{ url_for('logout') }}">üö™ Sair ({{ session['username'] }})</a>
    ^^^^^^^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1121, in url_for
    return self.handle_url_build_error(error, endpoint, values)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1110, in url_for
    rv = url_adapter.build(  # type: ignore[union-attr]
        endpoint,
    ...<3 lines>...
        force_external=_external,
    )
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/werkzeug/routing/map.py", line 924, in build
    raise BuildError(endpoint, values, method, self)
werkzeug.routing.exceptions.BuildError: Could not build url for endpoint 'logout'. Did you mean 'login' instead?
192.168.0.111 - - [10/Nov/2025 09:10:06] "[35m[1mGET / HTTP/1.1[0m" 500 -
[2025-11-10 09:10:10,048] ERROR in app: Exception on / [GET]
Traceback (most recent call last):
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/webstream_linux.py", line 222, in wrapper
    return f(*a, **kw)
  File "/home/vtsurgical/Documentos/stream/webstream_linux.py", line 238, in index
    return render_template("index.html", config=CONFIG, ia_enabled=IA_ENABLED, session=session)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/templating.py", line 150, in render_template
    return _render(app, template, context)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/templating.py", line 131, in _render
    rv = template.render(context)
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/jinja2/environment.py", line 1295, in render
    self.environment.handle_exception()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/jinja2/environment.py", line 942, in handle_exception
    raise rewrite_traceback_stack(source=source)
  File "/home/vtsurgical/Documentos/stream/templates/index.html", line 190, in top-level template code
    <a href="{{ url_for('logout') }}">üö™ Sair ({{ session['username'] }})</a>
    ^^^^^^^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1121, in url_for
    return self.handle_url_build_error(error, endpoint, values)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/flask/app.py", line 1110, in url_for
    rv = url_adapter.build(  # type: ignore[union-attr]
        endpoint,
    ...<3 lines>...
        force_external=_external,
    )
  File "/home/vtsurgical/Documentos/stream/.venv/lib/python3.13/site-packages/werkzeug/routing/map.py", line 924, in build
    raise BuildError(endpoint, values, method, self)
werkzeug.routing.exceptions.BuildError: Could not build url for endpoint 'logout'. Did you mean 'login' instead?
192.168.0.111 - - [10/Nov/2025 09:10:10] "[35m[1mGET / HTTP/1.1[0m" 500 -
üé• Codec ativo: MJPG em /dev/video0
‚úÖ C√¢mera iniciada: /dev/video0
